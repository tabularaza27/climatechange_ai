---
layout: post
title: "CCAI’s comments on the EU’s proposed Harmonized Rules on AI"
subtitle: "What role can the “high-risk” classification for AI systems play in addressing climate change?"
image: "/images/blog/eu-ai-regulation.jpg"
image_attribution: European Commission
authors: konstantin, lynn, jesse
article_type: "CCAI perspective"
topical_tags: EU, regulation, policy 
---

In April this year, the European Union [announced plans](https://www.wired.com/story/europes-proposed-limits-ai-global-consequences/) to regulate AI technology within its borders. As the bloc has already highlighted with GDPR, its extensive legislation protecting online rights and privacy, the EU sees regulation of digital technology as one of the key challenges of current times. 

The EU’s [proposed regulation](https://eur-lex.europa.eu/legal-content/EN/TXT/?qid=1623335154975&uri=CELEX%3A52021PC0206) focuses particularly on so-called [“high-risk” use cases of AI](https://www.wired.com/story/fight-to-define-when-ai-is-high-risk/). The most prominent examples, such as facial recognition software, involve acute effects on individuals from bias or abuse. But AI applications can be risky on a broader scale, as well, particularly if they affect our options to address climate change.

To highlight this connection, we at Climate Change AI published a [public comment](https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F2665623_en) on the proposed EU AI Act. We hope the final regulation will better reflect the many-faceted interplay between the potential of AI and the global challenge of a changing climate.

In particular, we believe the AI Act provides a unique opportunity to shape this interplay two ways:

First, climate change mitigation and adaptation should join other factors in informing whether an AI system is classified as “high-risk”. For example, if an AI solution leads to a substantial increase in greenhouse gas emissions, this should be reflected in its risk assessment. 

Second, reporting requirements for high-risk AI systems should be expanded to include effects on greenhouse gas emissions. Specifically, solution providers should be required not just to report on emissions from powering the system’s computations, but also to describe projected emissions impacts—both positive and negative—of the applications the system enables. This approach would leverage the opportunity of reporting requirements for high-risk AI systems to collect much-needed data for decision-making on decarbonization strategies.

You can read our full commentary, with more details on these suggestions and others, on the [website of the European Commission](https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F2665623_en). 
